# Zingtree - AI Service

## Resume

-   **Service Prefix**: `/ai-service/`
-   **Language**: [Python 3.11](https://docs.python.org/3.11/)
-   **Dependency management and packaging**: [Poetry](https://python-poetry.org/)
-   **Server**: [Uvicorn](https://www.uvicorn.org/) (ASGI) running on [Gunicorn](https://gunicorn.org/) (WSGI)
-   **Code Quality**: [PEP8](https://peps.python.org/pep-0008)
-   **Docblock format**: [Numpydoc](https://numpydoc.readthedocs.io/en/latest/format.html)

## Deployment

### Docker

The base image is at `Zingtree:python`. \
Dockerfile is based on a multistage build due to the use of Poetry.

### [Production] TBC

### [Dev] GH Action

The action `dev-build-push` will be triggered on any push to a branch following any of the next patterns:

-   `develop`
-   `release/**`
-   `hotfix/**`
-   `dev/**`

> **Note** \
> The action can also be dispatched manually.

## Automatic docs ([Swagger](https://github.com/swagger-api/swagger-ui))

Interactive API documentation generated by swagger can be accessed at `/docs`. \
This is **NOT** disabled at production since the service is not intended to be public.

## Acceptance

The `acceptance` action runs on all PR push.

> **Note** \
> The action can also be dispatched manually.

### Code Quality ([Flake8](https://flake8.pycqa.org/en/latest/))

Flake8 is a popular lint wrapper for python. Under the hood, it runs three other tools and combines their results:

-   `pep8` for checking style
-   `pyflakes` for checking syntax
-   `mccabe` for checking complexity

### Testing ([Pytest](https://docs.pytest.org/en/7.2.x/))

All the tests will run alongside this action. \
A coverage of **80%** is currently set up as part of the acceptance.

## Development notes

### Initial setup

1. Clone this repository.

    ```shell
    git clone https://github.com/Zingtree-Inc/ai-service.git
    ```

2. Make sure you have the latest at `zt_local`. Currently ai-service is not mandatory for local so, docker override is more complete.
3. Docker override.

    ```yml
    ai-service:
        image: zingtree/ai-service:develop
        volumes:
            - ../ai-service:/app
            - ../ai-service/.venv/lib:/venv/lib
        command: python -m uvicorn src.main:app --proxy-headers --host 0.0.0.0 --port 80 --reload
        ports:
            - "9088:80"
        environment:
            # OPENAI_ORG_ID: "org-id"
            # OPENAI_API_KEY: "api-key"
            # AWS_ACCESS_KEY_ID: "key-id"
            # AWS_SECRET_ACCESS_KEY: "access-key"
            ASSETS_S3_BUCKET: "zt-config-prod-na"
            AUTHORING_PROMPTS_TEMPLATES_FILE: "ai-service/prompt_templates.json"
            REDIS_URL: "redis://redis:6379"
        depends_on:
            - postgresql
            - db
    ```

    - `command`: this will override the server start at `Dockerfile` so it will reload each time a change is performed.
    - `ports`: Since is not intended to be a public service there will be no way of accessing the service directly, here we expose the service at port `9088`. Therefore you'll find the service exposed at `localhost:9088` for local development.

4. Install poetry ([docs](https://python-poetry.org/docs/)).

    > **Note** \
    > **If you have several versions of python make sure Poetry is using the correct one.**
    >
    > ```shell
    > poetry env use 3.11
    > ```
    >
    > **Make sure the virtual env is created in your work folder.**
    >
    > ```shell
    > poetry config --list | grep in-project
    > > virtualenvs.in-project = true
    >
    > // If false
    > poetry config virtualenvs.in-project true
    > ```
    >
    > After poetry is installed (Step 5.), there should be a `.venv` folder at `ai-service/.venv`

5. Navigate to the repository folder and install the dependencies.

    ```shell
    cd ai-service
    poetry install
    ```

6. Run the migrations
    ```shell
    cd zt_local
    docker compose exec ai-service python -m upgrade head
    ```

### Fake services

#### S3

S3 is used as the current external storage for assets and if the credentials are NOT set it will point to local-stack.

> **Note** \
> Only works when the enviroment is set to `local`
>
> ```env
> APP_ENV=local
> ```

> **Warning** \
> [TEMPORARY] The assets only exist in one of the env `env1`; until this config is in all env, replace:
>
> ```env
> ASSETS_S3_BUCKET: "zt-config-env1"
> ```

#### OpenAI

OpenAI has a fake response if the credentials are NOT set, this fake service will return fixed string.

> **Note** \
> This is **NOT** an option when the enviroment is set to `production` as it will be force to use OpenAI Library.

#### Slack

Slack has a fake response if the credentials are NOT set, this fake service will NOT send a request to the Slack API.

> **Warning** \
> **Be aware** this is available for all enviroment except `test`.

### Tools

> **Note** \
> Within the dev dependencies `flake8` and `black` are included.

### Makefile

A few commands

-   `make serve`: run uvicorn at 8055 (outside of docker swarm)
-   `make isort`, `make black`, `make flake8` and `make test`: Self explanatory
-   `make pre-commit`: Runs `isort` -> `black` -> `flake8` -> `pytest`

#### Linting ([Flake8](https://flake8.pycqa.org/en/latest/))

You can run the linting by executing `poetry run flake8` in the repository folder.

#### Formatter ([Black](https://pypi.org/project/black/))

You can run the linting by executing `poetry run black` in the repository folder.

#### Virtual environment

Poetry has an incorporated shell that can be started by executing `poetry shell` in the repository folder.

### Notes

#### Uvicorn (ASGI web server)

_Behind a TLS Termination Proxy_ \
`--proxy-headers` will tell Uvicorn to trust the headers sent by that proxy telling it that the application is running behind HTTPS, etc.

Wrapped in WSGI for security Ref. [Snyk Art. 3.](https://snyk.io/blog/best-practices-containerizing-python-docker/)

## Multiple Database Migrations with Alembic

Project supports multiple databases, specifically MySQL and PostgreSQL, and utilizes Alembic as the database migration tool.

### MySQL Database Migration

Configurations are in the `[mysql]` section of the `alembic.ini` file with the appropriate connection details for the MySQL database. \
Organize MySQL-specific migrations in the `alembic/mysql` directory.

**To generate a new migration for MySQL, run the following command:**

```bash
alembic -n mysql revision -m "Create table XYZ"
```

This will generate a new migration file in the alembic/mysql/versions directory.

**To apply migrations to the MySQL database, use the following command:**

```bash
alembic -n mysql upgrade head
```

This will apply all pending migrations to the MySQL database.

### PostgreSQL Database Migration

Configurations are in the `[postgresql]` section of the `alembic.ini` file with the appropriate connection details for the PostgreSQL database. \
Organize PostgreSQL-specific migrations in the `alembic/postgresql` directory.

**To generate a new migration for PostgreSQL, run the following command:**

```bash
alembic -n postgresql revision -m "Create table XYZ"
```

This will generate a new migration file in the alembic/postgresql/versions directory.

**To apply migrations to the PostgreSQL database, use the following command:**

```bash
alembic -n postgresql upgrade head
```

This will apply all pending migrations to the PostgreSQL database.

## Protobuf

To generate classes use:

> **Note**
> Not necessary but, currently the topic is used as the filename as well.

```sh
    cd {your_path}/src/proto
    protoc -I=./ --python_out=./ ./{topic}.proto
```
"# GenMan" 
